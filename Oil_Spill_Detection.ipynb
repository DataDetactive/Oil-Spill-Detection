{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from collections import Counter \n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'oil-spill.csv'\n",
    "dataframe = read_csv(filename, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>99.59</td>\n",
       "      <td>32.19</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>310</td>\n",
       "      <td>16110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>138.68</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6058.23</td>\n",
       "      <td>4061.15</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7.09</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>704</td>\n",
       "      <td>40140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.65</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>71.20</td>\n",
       "      <td>16.73</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38.80</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>120.22</td>\n",
       "      <td>33.47</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.21</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6.78</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>183</td>\n",
       "      <td>10080</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.27</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>289.19</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>87.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>132.78</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>45</td>\n",
       "      <td>2340</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.39</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1        2       3    4   ...  45        46     47    48  49\n",
       "0   1   2558  1506.09  456.63   90  ...   0  33243.19  65.74  7.95   1\n",
       "1   2  22325    79.11  841.03  180  ...   0  51572.04  65.73  6.26   0\n",
       "2   3    115  1449.85  608.43   88  ...   1  31692.84  65.81  7.84   1\n",
       "3   4   1201  1562.53  295.65   66  ...   1  37696.21  65.67  8.07   1\n",
       "4   5    312   950.27  440.86   37  ...   0  29038.17  65.66  7.35   0\n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize the number of examples in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataframe.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 896, 1.0: 41})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(target)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, Count=41, Percentage=4.376%\n",
      "Class=0, Count=896, Percentage=95.624%\n"
     ]
    }
   ],
   "source": [
    "#Notice the imbalance\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of each variable by creating a histogram for each:\n",
    "<html>\n",
    "    <p>in order to get a feeling of what are the main characteristics of certain features. and be able to             understand if it’s present any pattern in the data distribution if it’s present any pattern in the data          distribution, we can then tailor-made our Machine Learning models to best fit our case study.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVi0lEQVR4nO3dLY/cWLrA8cejS1rVqwlwqcBoFINITabR9gfoSAsiXbBsyYAELVsQNQkJWLagFw1rFDIfYEB4gQurUAYkgzYgIFIHROpSSHZ8QcYdl9vl8/5i+/9Dmemyz3l87KfOOWX7FHVdCwAgvm9SVwAA5ooEDACJkIABIBESMAAkQgIGgERIwACQyP+YfLgsy3q5XMpisQhVHxER2e12RmVst9vruq6XOp8ty7Kuqsq4DBc6ZZnEIOK/LXwdD1UcRVH8XUT+LiJydHT05++//15+//13+eabdH2Bbvm//fbbLNqiLdZ1EePati0r1HZDMRgl4Kqq5PHT5/LvV183+8+//te0nkrr9VrOz8+1P18UxVvdz1ZVJZvNRn76+ZfbOELE0KYTj0kMIv7bwvSYH6KKo67rKxG5EhE5OzurN5vNXtnVs5d7nw/dNiJ3Y7dpi8vLS+3j146xL75YbbFXp0jXRYxre6gsnfPL9vgf2m4oBqMEDOCLdk9+tVrJzc2NrNdrrW0vTj/f/rtvG5N9YdyUCbh7oq2O9k+gn37+5fbfp99966VSnIDIXbcnf3x8rN1retLuAf94dxtfPeA56Oandt7oyyPt3CXi9wvQZjtlAu6eaO8/yd6wt63vZLLBCQhARzc/tfNGXx550p2C8PgFaLMdd0EAQCLMAQOYtO4PbzkhAY+Iaj7eZd6ceXcgPhLwiKjm413m4HOdd1fdsgWMGQkYo5HiHuHQphjTmBz6go/VLrNIwH23qrSH76GH3gzvkaMU1wXXwr5ZJOC+W1X2nvjxdPvcIbkO78eO6Qk3Ka4LroV9XhMwwyngrpx/hcdXTTt9GQHE6ZsGLYUeCmKZypd/9eylXJx+lifPXo42BuibxRQE8vbq3cc7Tyhh31S+YLAvWgLmBMrXFHtdqUdfPqYdhvYx9LeptKGt9lRC7l/s9ICxhy9KO/TiYSNZAk7dQ5kz294ZbQb4RQ94QkIkSH7BB/Sug4vTz3JuuF8S8ESFnkpgqgJwl0UC7l7MLx7FWattTujJAvkp6roe/kDrcUURORGRDyJyHbhepWEZ93UXgpQvMbyxKMOFTlmDMYgEbwtfxyP3tujTLZ+2CCfGtW1bVqjtDsagTMB3NiiKTV3XZxaVm10Zocvyud+YxyOnsn2VT1vksX8fZcXcjhUxACAREjAAJGKTgK+812K6ZYQuy+d+Yx6PnMr2VT5tkcf+fZQVbTvjOWAAgB9MQQBAIkb3Ad+7d69+8OBBqLoY2+12slgsZLvdXqtuG2qUZVlXVXW7bYj62DCJQSR8W9jGYhKH7xh8tWlubdFmEmPKtmi4tonptb1cLr1f1yqqGIdiMErAq9VKNpvNwb/Hfjqqebt+URRvdbepqko2m83+m/891dPlbf8mMYiEbwvbWEziaGLw9Qi1r9UWQrdFW8h2sWkLXbrnl2ubmF7bl5eXg+WFyFGqGIdiYAoCABLJ4lFkAPnL8XH27sKiqkU/mwVHGz4WCHVZaJQEDGC0uguLHh8fD04HdN/Z7GPhUZdpFhIwYKHd81oul0a9rjbTnhPLuk8LCRiw0O55nZyc1Ca9rjbTHpjPZd1NvkRE7L5I+MIYpkzALt/0P/38y+2/T7/71rKKh9G4gD2TLxERuy8Sn18YIaRe5UWZgFN90+vIvXF9c/kyzGWo2xdDu64uZfKFjLFhCmJEXL4MUw512/piaNfV5Yt6bl/IGL9ZJODurSrr9VpWR197ib56Tal7YDneJgTgsFkk4O6tKufn5/tPwnmaHsm5B5Z6rgv9WFtv3maRgAHMV84jQxIwAEiaUSIJGIAzprjsREvAzHUBGItY+Yq3oQFAIs49YNsJboYs6TAayRfXxbwwB4ys8OWQj5zvHoht6Fi8eGS/AkcWCZiLLi16XfCpfT65JKc5yCIBd5EQ9NBDyUeItujb58XpZ3ny7GWw68J3HK/efTz4jpixxKDSjtE0JuWy9O3HeEXkBxH51byKwZQici0i94cW7uvEcCIib1rbhqiPjcEYRKK3hW0sJm3hOwZfbZpbW7SZxJiyLRqubWJ6bX9wLM+GKsaDMSgT8N6Hi2JT1/WZYeWCcalPiFhiHp/QZcWIxXcZqc7PKbT72PabS3muZXIbGgAkQgIGgERME/BVkFrYc6lPiFhiHp/QZcWIxXcZqc7PKbT72PabS3lOZRrNAQMA/GEKAgASMboPuCzLerlcymIR5+bq3W6nVdZ2u71W3TbUKMuyrqpKe98h9JVtEoNI/LZoqI5bLm3hsk+btqiqyqgM2/qZbGfaFlO4tkPGYNtmQzEYJeCqquTy8vLgqg++n2jTXWGiKIq3uvusqko2m83+ihiRH/boi8skBpEvcTx++vw2BpE4cajaJJe2cFmdRCeG7jJXj58+3/u7ahXwm5sbOT4+Nq6byXYPHz40aouha/vO5x2v9VDXtkkMImYPfdmeU0MxZPkkHJC77jJX7S9CEfUyV7YXc87LXsHcLBJwrEU5daVevBOwMYVH33OLYRYJWLUop7za7X0+9FCeXgwAkZkkYFO8DAhADCRgAKPVnV5UTe810459VNOCIaYOScBAAEOjqOrZy+CvldQRM3l1+Upm3enF4+Pjwem9Q6/GFAn3w+kQZQI2aaRuA7ke4Bx+rOJl8ZiqmMmri99BvlAmYFUj7Scos1txVGgkAFPGFMSIdEcj7VvpROLcTuc6Kol1S2AOoydAJWgC5m4Cv7qjkfefZP9JOMcRhw7XUYnqlkBfMTB6gqkU+YoeMBBYbjf/Ix+8DQ0AEqEHbIhpFaTQnHc53L7Wh+vCDj1gAEiEHjAwQvQ4p4EE7ICHNAC4iJaASVbAuMz57o1Y+co4Ab9693HwkcQ5Y1gIcB2YSDYFMfVGoscPHUPniW4P1Oe55rvXm+I6CNFzb79AqcslJuWy9O1HR0XkREQ+iMi1dYlmSs2y7g8t3NcTwxuDfYfQV/ZgDCLJ26KhOm65tIXLPm3a4o1hGbb1M9nOtC2mcG2HjMG2zQ7GoEzAdzYoik1d12cWlTAWsqyYcYQqO0UMIcocyz59sq3fVK6JUGWN7fhwHzAAJEICBoBEbBLwlfdapCkrZhyhyk4RQ4gyx7JPn2zrN5VrIlRZozo+xnPAAAA/mIIAgESM7gMuy7Kuqkp2u50sFosgFbLZ93a7vVbdNtTwGYPPfZjEIPI1DpMyXOqny6YtXPk6H3Nui1jXhc/yXbZrtn39+rX38yl2/hpqB+NFOS8vL+Xm5kaOj49F5MuTcY3T7761r/kf2vvW9fDhw7e6n62qSjabjZcVE9orOYjY3ZDd1KMoCu0YRL7GcfDvrRvGL04/yz9+/Ktx3dr102USR18MNjfu+1r9IlRb9JWhtd/WsXjxaGEco8+2sD2HXNpmvV5bXduDn/njgYrbFVg8PxjSF+9QOxgvynl+fr5XyN6TIa92e9u6JCQAmDrWhENyc37pS0p9C6S2tRd8XR3ZLZjqsjjqzc2N1XZjwusogZnqG922PelMQfzNYmTqOgURWupOIgkYwC1GI3GRgEdENWRs8zF8FHEbQgIYRgIeEdWQsc3H8FGEH0WBkEa3IkbqORvA1dTP4e7tcyGZjApFvnRGVkf7I8SGj5Ge6YiRHjCi6rtg+i6Ghs7J7GuaxGQ/phd+u4yL0//e/rfuNBJTQf1MRoUiX0aG7fuA2/7z4/C2OkxHjLNIwH0Xi48TuvtNGvs2nTHqu2CGlrjSuSh8P4ihw/TCb5fx7//7er/8UHxPHB/EQP5mkYBVD5PYuvMknMU3KHOswHzNIgHDXnsR1inOVyKuqc9/mzJOwEOL0wEA9NEDHrEQK85293lx6rxLQMsce8ckYMyar1umUiy/jvEjAQMjR/L3I0UPnAQ8E3Mc3gEieb/fgiWJACAResDQ7iHQi8ZcxJrWSZaAuZj9y3moBeAu5bL07cd4ReRERN6ISCki14HqZLPv+0ML9wWMwec+BmMQORiHSRku9dNl0xaufJ2PObdFrOvCZ/ku2zXbLgKcT7Hz18F2UCbg3o2KYlPX9ZlF5ZLu23c5uewjZBmx2sOFrzrm3Bap2yFFvUPFnFP+4kc4AEiEBAwAidgm4CuvtYi3b9/l5LKPkGXEag8XvuqYc1ukbocU9Q4Vczb5y2oOGADgjikIAEjE6D7ge/fu1Q8ePAhSkd1uJ4uF3ctQttvtteq2oUZZlnVVVUb7d6mb7r5MYhAxi8Nn/VVl2LRFjPp1DZVp0xbL5dJrDD6OydzaImQMofKTUQJerVZy/Zd/7v0/Xw9RuKwMURTFW93PVlUlm83GaP+H6mbztMyhfZnEIGIWh8ux1X1gpinDpi1CrwrSF8NQmTZt8fjp8/3VURyvCx/HZG5t0cRwZ6UaDzkqVH5iCgIAEiEBA0AivIwHUYVaoXpI38rVc1uNug9tkR4JeET6LhgdLid43wXjUkaoFaqHtNcvbFauZjVq2iIHs0jAtomrcSi5tJOTyHCCUu1LR98Fo8PlBO+7YHyXoYuVH/JBW/gxiwRsm7gah5JLd2XooQSl2heA+VEm4HbvcblcynOLXp+OOc8DAZgnZQJu9x5PTk7q9v11Inq9Ph1T6BlO/SXzU48PiG0WUxDQx6oaerq/K6yO9H+w1MGIUE/f7zu+20IkXHuQgAPhR4rwUvbIu78rvP8k+09fOY4MxzYiTNUWfb/v3HkSzsMoPVR7kIAxSfTk80A7DCMBY9aY187HHNuCBAx6KUAivAsCABKhB2yI3iIAX+gBA0Ai9IBlfreM0YsH8uCcgKf4y+UUY/Ktm8RfPIq7jA0wBbPtAU+9F9iO7+L0850XB81Vc1w4JunRFhrL0rcf9RORH0Tk10B1KUXk2nLb+0ML93ViOBGRNxHrpruvwRhEnOLwWX9VGTZtEaN+XUNl2rTFh4H92fBxTCbfFhFjCJKflAl478NFsanr+syyEsn27cpn3VLEGaNMlzKmcExy31/O5Y7h2IU6LtwFAQCJkIABIBHTBHwVpBbh9+3KZ91SxBmjTJcypnBMct9fzuWO4dgFOS5Gc8AAAH+YggCARIzuAy7Lsl4ul7JY5HXT/Xa7vVbdNtQoy7Kuqkp2u10WcTT1MIlBJExb+DgmNm3hWhffn7Vpi0Nx2NRRRXdfY7kuhsocSwwih+MYisEoAVdVJY+fPt9/23wGT4oVRfFW97NVVclms/HyhnsfjzA39TCJQSRMW/g4JjZtMVQXnacSTeqt81mbtjgUh0m5InpPYeruy6Yt2qtJxLq2h+JxjUEkfRxDMcz2STjARd9aZIe8evdRVkciP/38i4iInH737cHP6qxlxnpx00ECBiz0rUV2yJNnL+Xi9PPXnuXAGmXtR3IPfW5s68XhsFkk4L7eio9eRLu3ImK3+iq9mfnhZU9ozCIB9/VWfPQiui8QsVl9ld4MMF+zSMDIh+7caTMy8D0nyogDOSEBIyrdudNmZOB7TpQRB3JCAh6Rbu9xdaT3q7kueofjZHs7ZN9opH1OxToX5nzekYBHpNt7fP9J9u93tJiDbqN3OC99o5G9+4Adzyddcz7vlAk4dK8rlVfvPt4Ob/klOh+skgATql68SN49eWUCDt3rAmy1k/V52qrMbmHXXKh68SJ59+R5GQ8AJMIcMDAC3UVWz9NVBR7RAwaAROgBI7nu/CkwF/SAASAResCYNV6Mg5RIwBNCMlFr3/+NYdxaFx5TEACQCD3gBNo9ixeP0q9Lhzzl9uMkIyz/lMvStx/1E5ETEfkgIteB62XqpK7rPx36Y08Mb0SklDziaOpxX7X4YIS28HFMBuM40BaudfH9WZu2OBSHSbm6dPdl0xYprouhMscSgwyUezAGZQK+s0FRbOq6PrOoXDA2dcolDpd6+I4hl2MiYlaXUJ/1yWe5IWNIcXymch7blMscMAAkQgIGgERsEvCV91q4s6lTLnG41MN3DLkcExGzuoT6rE8+yw0ZQ4rjM5Xz2Lhc4zlgAIAfTEEAQCJG9wGXZVkvl0tZLPK5d3W328nr16+vVbcNNcqyrKuqkt1u5zUO1/1tt1vtGETCt4VtPCZxhGoLW009TNvi3r179YMHD0JWTanvGNq0hc5+fdHZt48YfNfJdD9DMRgl4Kqq5PHT5/tvm098Q/Z6vZaHDx++1f18VVWy2Wz2177yEIPrulZFUWjHIBK+LWzjMYkjVFvYamI2bYvVaiXXf/nn3v+LHUdfe9m0hc5+fenuu+9BD5sYXB6h9hVvez9DMTAFAQCJ8CgygEnL+RFqesAAkAg9YMBC+x0Ey+VSnreWQReJtxR6w2ZJdKRHAgYstJdDPzk5qds/horEWwq9EfLHMoRDAgYwWu2RyGq1kvV6LRed0UibapTgayShux8S8Ih0T7bVkeydbD6HoAxpMQbtkcjZ2Vl9fn4+uOKJamQS4ja0IbNIwH3fku3kFfMbz0X3ZHv/SfbvA/Y47A01pI3RFrbm9qXT1xZdIY9Jd9+hOhM5UybgmL0uGzc3N8rP9H1L7t387yFxMQenJ0Zb2JpbG/a1RVfMBzHaPdeU50FMygQcs9dlI/UXAADY4j5gAEhkFnPAACByd6FT30/GNfu/OP0sT569VO6fHjAAJEICBoBEmIIAAsj5BTDIBz1gAEiEHvCE0Osy1z5mLx6lX5UjNc6huEjAEv6XUcwb5xcOIQEDkdHLREO5LH37UWQRORGRDyJyHbheJkoRWQwt3NcTw5s/tvMZh+v+7qsWH4zcFrbxDMYRqS1sNfUwbYsfROTXwHVT6TuGNm2hs19fdPbtIwbfdTLdz8EYlAn4zgZFsanr+syxct7Y1sd3HCmOS8gyY8aTyzmVy7lkI1QdpnKO6fJVJ939cBcEACRCAgaARGwS8JX3WrixrY/vOFIcl5Blxownl3Mql3PJRqg6TOUc0+WrTlr7MZ4DBgD4wRQEACRidB9wWZb1crmUxSKPJ4Z2u50sFgvZbrfXqtuGACA3Rgm4qip5/PT5/ooYCW8kb5Y0KYribbJKAIAlpiAAIBESMAAkQgIGgERIwACQCAkYABIhAQNAIiRgAEiEBAwAiSgfxGi/8Hi1WsnqSOTi9PPt39frdbDKqdzc3CQtHwBcKBNwXddX8sebfc7Ozur3n2T/Sbgfz4NVTqV5Eg4AxogpCABIhAQMAImQgAEgERIwACRCAgaAREjAAJAICRgAEiEBA0AiRksS5aB69vL23y8e5bE2HQDYUC5L334UWUROROSDiFwHrpeuUr7U5T6LcgIYG2UCvrNBUWzquj4LVB8jOdUFAEwxBwwAiZCAASARmwR85b0W9nKqCwAYMZ4DBgD4wRQEACRCAgaAREjAAJAICRgAEiEBA0Ai/w/ks0va9/UWRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 56 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a histogram plot of each variable and science our variables are features of the images we do not need label \n",
    "ax = dataframe.hist()\n",
    "#disable axis labels\n",
    "for axis in ax.flatten():\n",
    "    axis.set_title('')\n",
    "    axis.set_xticklabels([])\n",
    "    axis.set_yticklabels([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<ul>\n",
    "    <li>Running the snippet previous code creates the figure with one histogram subplot for each of the 50 variables in the dataset.</li>\n",
    "    <li> We can see many different distributions, some with Gaussian-like distributions, others with seemingly exponential or discrete distributions.</li>\n",
    "    <li> Depending on the choice of modeling algorithms, we would expect scaling the distributions to the same range to be useful, and perhaps the use of some power transforms.</li>\n",
    "</ul>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test and Base line result (Bench Mark for our Case): \n",
    "   <html>\n",
    "        <h5 style=\"color:red\">remember that we are handel unbalanced data So: </h5>\n",
    "    <h6> We will evaluate candidate models using repeated stratified k-fold cross-validation: </h6>\n",
    "      <ul>\n",
    "        <li>Stratified means that each fold will contain the same mixture of examples by class, that is about 96% to 4% non-spill and spill. Repeated means that the evaluation process will be performed multiple times to help avoid fluke results and better capture the variance of the chosen model. We will use three repeats.</li>\n",
    "     </ul>\n",
    "    <h6> We are predicting class labels of whether a satellite image patch contains a spill or not. There are many measures we could use, although the authors of the paper chose to report the sensitivity, specificity, and the geometric mean of the two scores, called the <span style=\"color:blue\"> G-mean</span>: </h6>\n",
    "    <ul>\n",
    "        <li>Sensitivity = TruePositives / (TruePositives + FalseNegatives)</li>\n",
    "        <li>Specificity = TrueNegatives / (TrueNegatives + FalsePositives)</li>\n",
    "        <li>G-Mean = sqrt(Sensitivity * Specificity)</li>\n",
    "        <li style=\"color:red\"> Note: poor performanc means low G-mean score.</li>\n",
    "    </ul>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset and split the columns into input and output variables. \n",
    "def load_dataset(full_path):\n",
    "    # load the dataset as a numpy array\n",
    "    data = read_csv(full_path, header=None)\n",
    "    \n",
    "    # drop unused columns see above you will notice that column 22 have the same value and column 1 is the index\n",
    "    data.drop(22, axis=1, inplace=True)\n",
    "    data.drop(0, axis=1, inplace=True)\n",
    "    \n",
    "    # retrieve numpy array\n",
    "    data = data.values\n",
    "    \n",
    "    # split into input and output elements\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function that will evaluate a given model on the dataset and return a list of G-Mean scores for each fold and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # define the model evaluation metric\n",
    "    metric = make_scorer(geometric_mean_score)\n",
    "    \n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to asamble what we have done and use DummyClassifier as our bench mark if you don't understand what is bench mark and what is used for here is another broject i desccused about it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean G-Mean: 0.507 (0.167)\n"
     ]
    }
   ],
   "source": [
    "full_path = 'oil-spill.csv'\n",
    "X, y = load_dataset(full_path)\n",
    "model = DummyClassifier(strategy='uniform')\n",
    "scores = evaluate_model(X, y, model)\n",
    "print('Mean G-Mean: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <p style=\"color-background:red\">\n",
    "        In this case, we can see that the baseline algorithm achieves a G-Mean of about 0.50, close to the theoretical maximum of 0.5. This score provides a lower limit on model skill; any model that achieves an average G-Mean above about 0.50 (or really above 0.5) has skill, whereas models that achieve a score below this value do not have skill on this dataset.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <p>In this section, we will evaluate a suite of different techniques on the dataset using the test harness developed in the previous section.</p>\n",
    "    <p>The goal is to both demonstrate how to work through the problem systematically and to demonstrate the capability of some techniques designed for imbalanced classification problems.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <p>We will evaluate the following probabilistic models with default hyperparameters in the dataset:</p>\n",
    "    <ul>\n",
    "        <li>Logistic Regression (LR)</li>\n",
    "        <li>Linear Discriminant Analysis (LDA)</li>\n",
    "        <li>Gaussian Naive Bayes (NB)</li>\n",
    "    </ul>\n",
    "    <p><span style=\"color:red\">NOTE: </span>Both LR and LDA are sensitive to the scale of the input variables, and often expect and/or perform better if input variables with different scales are normalized or standardized as a pre-processing step.so we will use <span style=\"color:blue\">StandardScaler </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "models, names, results = list(), list(), list()\n",
    "# LR\n",
    "models.append(Pipeline(steps=[('t',StandardScaler()),('m',LogisticRegression(solver='liblinear'))]))\n",
    "names.append('LR')\n",
    "\n",
    "# LDA\n",
    "models.append(Pipeline(steps=[('t', StandardScaler()),('m',LinearDiscriminantAnalysis())]))\n",
    "names.append('LDA')\n",
    "\n",
    "# NB\n",
    "models.append(GaussianNB())\n",
    "names.append('NB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.672 (0.203)\n",
      ">LDA 0.755 (0.147)\n",
      ">NB 0.707 (0.202)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "    # summarize and store\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <h5>Logistic Regression</h5>\n",
    "    <span>Notice that logistic regression is sensitive to the scale of input variables and can perform better with normalized or standardized inputs </span>\n",
    "    <p>we will try to make the the logistic regression work well by balance the class</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Balanced models\n",
    "Bmodels, Bnames, Bresults = list(), list(), list()\n",
    "# LR Balanced\n",
    "Bmodels.append(LogisticRegression(solver='liblinear', class_weight='balanced'))\n",
    "Bnames.append('Balanced')\n",
    "# LR Balanced + Normalization\n",
    "Bmodels.append(Pipeline(steps=[('t', MinMaxScaler()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "Bnames.append('Balanced-Norm')\n",
    "# LR Balanced + Standardization\n",
    "Bmodels.append(Pipeline(steps=[('t', StandardScaler()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "Bnames.append('Balanced-Std')\n",
    "# LR Balanced  + Power\n",
    "Bmodels.append(Pipeline(steps=[('t1', MinMaxScaler()), ('t2', PowerTransformer()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "Bnames.append('Balanced-Power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Balanced 0.841 (0.118)\n",
      ">Balanced-Norm 0.836 (0.088)\n",
      ">Balanced-Std 0.834 (0.129)\n",
      ">Balanced-Power 0.862 (0.124)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model\n",
    "for i in range(len(Bmodels)):\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, Bmodels[i])\n",
    "    Bresults.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (Bnames[i], mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "pyplot.boxplot(Bresults, labels=Bnames, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
